<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>The Interface of Intelligence</title>
	<link rel="icon" href="/img/favicon.svg">

	<link rel="stylesheet" href="/css/reset.min.css">
	<link rel="stylesheet" href="/css/reveal.min.css">
	<link rel="stylesheet" href="/css/bootstrap-icons.css">
	<link rel="stylesheet" href="/css/style.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="/css/nord.min.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<br>
				<h1 class="r-fit-text">The Interface of Intelligence</h1>
				<h3 class="r-fit-text">User-first approaches in open-source AI software design</h3>
				<br>
				<br>
				<br>
				<br>
				<h3>Haifeng Jin</h3>
				<aside class="notes">
					The title of this presentation is "The Interface of
					Intelligence: User-first approaches in open-source AI
					software design". This presentation has everything you need
					to know if you want to start your own open-source AI-related
					project.
				</aside>
			</section>
			<section>
				<h1>What is open source?</h1>
				<aside class="notes">
					Before we dive into the main content of the presentation.
					Let us have a quick review of "What is open source".
				</aside>
			</section>
			<section>
				<h1 class="r-fit-text">Access</h1>
				<aside class="notes">
					And the first keyword defines open source is who can access
					the code. If the author put the source code of the project
					on the internet for everyone to read, it is usually
					considered open source. The usages are often protected by
					their open-source licenses. For example, some of the
					licenses may prevent you from using their code to make
					money.
				</aside>
			</section>
			<section>
				<h1>Umidigi F2 kernel source code</h1>
				<aside class="notes">
					However, there are always corner cases. The Umidigi F2 is a
					fork of the Linux kernel. And the Linux kernel is protected
					by the GPLv2 open-source license that requires all the code
					using it to be open-source. So, they have to open source
					their code according to the license. One day a user send an
					email to request their code since they could not find it on
					the Internet. Guess what reply the user got?
				</aside>
			</section>
			<section>
				<h1>"You can request the shareable source code at our office." </h1>
				<h2>Ben, UMIDIGI</h2>
				<aside class="notes">
					This is the reply they got. "You can request the shareable
					source code at our office." Replied by their employee. It means
					the user may need to apply a visa and book an air ticket and
					hotel to get the source code.

					And with all these intentionally created difficulties, the
					code is still considered open source. Pretty interesting.
				</aside>
			</section>
			<section>
				<h1>What is the website for open source?</h1>
				<aside class="notes">
					To open source the code, we usually just put it onto the
					internet. But where to put it? What is the website for open
					source? Which one is the most popular one?
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="width:30%;">
						<img src="/img/sourceforge.svg">
						<h2>SourceForge</h2>
					</div>
				</div>
				<aside class="notes">
					A really popular website a long time ago was the SourceForge.
					Let's have a quick show hands of who has heard about this
					website before. This was the number one open-source website
					recommended by a professor during my undergrad study. It is
					mainly a website for users to publish the source code of
					their software. But we all know the story afterwards.
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="width:30%;">
						<img src="/img/github.svg">
						<h2 style="padding: 50px;">GitHub</h2>
					</div>
				</div>
				<aside class="notes">
					That GitHub took over a few years later. The reason why
					GitHub could win was because it had something more than just
					accessing the code, which brings us to the second keyword of
					open-source, which is
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<p class="r-fit-text">Collaboration</p>
				</h1>
				<aside class="notes">
					Collaboration. GitHub has a far better user experience for
					collaboration between the open-source developers. On GitHub,
					you can easily collaborate with other developers who share
					the same interest. Everyone can contribute to every project.
					It is where the code are combined together with the
					community developing it. All in one place.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<p>Open Source:</p>
					<div class="centered">
						<div style="width: 20%">
							<p>Access</p>
						</div>
						<div style="width: 10%">
							<p>+</p>
						</div>
						<div style="width: 40%">
							<p class="nowrap">Collaboration</p>
						</div>
					</div>
				</h1>
				<aside class="notes">
					So open source is about access to the source code and
					collaboration between the developers.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<div class="centered">
						<div style="width: 20%">
							<p>Open</p>
							<p>Access</p>
						</div>
						<div style="width: 10%">
							<p>+</p>
						</div>
						<div style="width: 40%">
							<p>Open</p>
							<p>Collaboration</p>
						</div>

					</div>
				</h1>
				<aside class="notes">
					More precisely, it is about open access and open collaboration.
					Everyone can access the code, and every can contribute code.
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="width: 70%; transform: translate(0, -5%);">
						<img src="/img/cathedral.png">
					</div>
				</div>
				<aside class="notes">
					There is this really popular book considered the ultimate
					guide for open-source projects. It is called "The Cathedral
					and The Bazzar". It tries to contrast between proprietary
					software with open source software.
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="width: 30%; text-align: right;">
						<h1>Cathedral</h1>
					</div>
					<div class="centered" style="width: 10%; margin: 5%">
						<div class="fragment custom blur-out"
							style="background-color: var(--r-main-color); height: 400px; width: 5%;"></div>
					</div>
					<div style="width: 30%; text-align: left;">
						<h1>Bazzar</h1>
					</div>
				</div>
				<aside class="notes">
					It pictured the proprietary software developed by big
					companies as cathedrals, which requires top-down management
					and investment of huge amount of resources.

					On the other hand, open source software are descriped as
					bazzars, which are formed organically based on people's
					needs.

					It was so true if you apply this framework to the Unix vs
					Linux case. However, if we look back at it from today. The
					boundary between the cathedrals and the bazzars is blured.
					If all the popular open-source software is developed by
					gropus formed organically from the community, why did we
					see ...
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width:25%;">
						<img src="/img/android2.svg">
					</div>
				</div>
				<aside class="notes">
					Android developed by Google.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width:25%;">
						<img style="width:70%;" src="/img/android2.svg">
					</div>
					<div style="width:25%;">
						<img style="width:70%;" src="/img/pytorch.svg">
					</div>
				</div>
				<aside class="notes">
					PyTorch developed by Meta.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width:25%;">
						<img style="width:60%;" src="/img/android2.svg">
					</div>
					<div style="width:25%;">
						<img style="width:60%;" src="/img/pytorch.svg">
					</div>
					<div style="width:25%;">
						<img style="width:60%;" src="/img/keras.svg">
					</div>
				</div>
				<aside class="notes">
					Keras.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width:25%;">
						<img style="width:50%;" src="/img/android2.svg">
					</div>
					<div style="width:25%;">
						<img style="width:50%;" src="/img/pytorch.svg">
					</div>
					<div style="width:25%;">
						<img style="width:50%;" src="/img/keras.svg">
					</div>
					<div style="width:25%;">
						<img style="width:50%;" src="/img/tensorflow.svg">
					</div>
				</div>
				<aside class="notes">
					and TensorFlow. These are all open-source software developed
					by big companies. They are build the same way as we build
					cathedrals but they are open-source at the same time.

					It brings us to the second question about open source.
				</aside>
			</section>
			<section>
				<h1>Why do we open source?</h1>
				<aside class="notes">
					Why do we open source?
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width:40%;">
						<img width="100%" src="/img/android2.svg">
					</div>
				</div>
				<aside class="notes">
					Let's use Android again as an example to illustrate this.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width:40%">
						<img width="70%" src="/img/android2.svg">
					</div>
					<div style="width:40%">
						<img width="70%" src="/img/google-play.svg">
					</div>
				</div>
				<aside class="notes">
					When we use Android, we usually use it combined with the
					Google Play Store, and many other services provided by
					Google.

					Android is open source. So the smartphone companies want to
					use it. It attracted a large number of cell phone users to
					this open-source operating system. Many of them would use
					the operating system combined with the Google services like
					the Play Store. And for every dollar they spent in the Play
					Store, Google gets a share of it.

					This is a very typical scenario of how they make money with
					open-source software.
				</aside>
			</section>
			<section data-auto-animate id="android">
				<div class="centered">
					<div style="width:40%">
						<div class="fragment custom move-out-to-left" data-fragment-index="1">
							<img width="50%" src="/img/android2.svg">
						</div>
						<br>
						<h2>Free code</h2>
					</div>
					<div style="width:40%">
						<div class="fragment custom move-out-to-left" data-fragment-index="1">
							<img width="50%" src="/img/google-play.svg">
						</div>
						<br>
						<h2>Paid service</h2>
					</div>
				</div>
				<aside class="notes">
					I call this the "free code and paid service" model. The code
					is free out there to attract more users, who can be
					potentially funneled into users to their paid services.

					This model almost applies to all the open source software
					developed by big tech companies.
				</aside>
			</section>
			<section data-auto-animate id="chrome">
				<div class="centered">
					<div style="width:40%">
						<div class="fragment custom move-in-from-right" data-fragment-index="1">
							<div class="fragment custom move-out-to-left" data-fragment-index="2">
								<img width="50%" src="/img/chrome.svg">
							</div>
						</div>
						<br>
						<h2>Free code</h2>
					</div>
					<div style="width:40%">
						<div class="fragment custom move-in-from-right" data-fragment-index="1">
							<div class="fragment custom move-out-to-left" data-fragment-index="2">
								<img width="50%" src="/img/google.svg">
							</div>
						</div>
						<br>
						<h2>Paid service</h2>
					</div>
				</div>
				<aside class="notes">
					For example, Chrome is open-source to attract more users to
					the Google search engine.
				</aside>
			</section>
			<section data-auto-animate id="tensorflow">
				<div class="centered">
					<div style="width:40%">
						<div class="fragment custom move-in-from-right" data-fragment-index="1">
							<img width="50%" src="/img/tensorflow.svg">
						</div>
						<br>
						<h2>Free code</h2>
					</div>
					<div style="width:40%">
						<div class="fragment custom move-in-from-right" data-fragment-index="1">
							<img width="50%" src="/img/google-cloud.svg">
						</div>
						<br>
						<h2>Paid service</h2>
					</div>
				</div>
				<aside class="notes">
					TensorFlow can potentially attract more users to the Google
					Cloud Platform, especially using their TPUs on the cloud.

					But this case is a little different. I don't think Google
					had a clear business model when they first open source
					TensorFlow. Otherwise, both TensorFlow and the Google Cloud
					would be much more successful than it is today.

					But if that is the case,
				</aside>
			</section>
			<section>
				<h1>Why open source TensorFlow?</h1>
				<aside class="notes">
					why was TensorFlow open sourced in the first place?
					I do not have the exact information but I believe it was a
					mix of factors.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<ul>
						<li>Professional branding</li>
					</ul>
				</h1>
				<aside class="notes">
					First, it is about professional branding. Let everyone
					working in machine learning use technologies from Google.
					It will project Google as a leader of the machine learning
					revolution. It helps Google recruit the best talents on the
					job market.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<ul>
						<li>Professional branding</li>
						<li>Keep engineers happy</li>
					</ul>
				</h1>
				<aside class="notes">
					Secondly, open source keeps the engineers happy. It gains
					exposure to the work of the engineers. Everyone on the
					internet can read their code and use their software. It
					helps them gain impact. It lowers the attrition rate and
					also helps recruiting as well.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<ul>
						<li>Professional branding</li>
						<li>Keep engineers happy</li>
						<li>Full control over its infra</li>
					</ul>
				</h1>
				<aside class="notes">
					The third one, which I believe is the most important one, is
					about having full control over its machine learning
					infrastructure. If TensorFlow is not open-source, there will
					be some other framework out there gaining popularity in the
					community. People at Google may want to use that instead of
					TensorFlow. If too many people use something not developed
					by Google at Google, then Google lose full control over its
					infra.

					We will talk more about this in a bit.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>
					<ul>
						<li>Making money</li>
						<li>Professional branding</li>
						<li>Keep engineers happy</li>
						<li>Full control over its infra</li>
					</ul>
				</h1>
				<aside class="notes">
					And plus making money. These are the four most important
					reasons of why people want to do open source.

					With all these goals in mind, how did Google do?
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1>TensorFlow dominated the market</h1>
				<aside class="notes">
					TensorFlow dominated the market
				</aside>
			</section>
			<section data-auto-animate>
				<h1>TensorFlow dominated the market</h1>
				<h1>Theano, Caffe2, MXNet went obsolete</h1>
				<aside class="notes">
					And all other frameworks at the time, including Theano,
					Caffe2, MXNet, went obsolete. As we all thought TensorFlow
					is the ultimate solution for deep learning.
				</aside>
			</section>
			<section>
				<h1>PyTorch took away half of the users</h1>
				<aside class="notes">
					PyTorch took away half of the users. Now, we see that there
					might not be a framework that works forever. The deep learning
					frameworks are all transitory.
				</aside>
			</section>
			<section>
				<div class="r-fit-text">
					<h1>Full of</h1>
					<h1>opportunities</h1>
				</div>
				<aside class="notes">
					The landscape of open-source AI changes drastically every
					few years. There are still full of opportunities.
				</aside>
			</section>
			<section>
				<h1>How to excell in open source?</h1>
				<aside class="notes">
					One question we want to ask here is "How to excell in
					open-source AI"? What are the factors deciding the dynamics
					of the landscape.
				</aside>
			</section>
			<section>
				<h1 class="r-fit-text">UX</h1>
				<aside class="notes">
					The short answer is "user experience is the key".
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width: 50%; text-align: right;">
						<h1>TensorFlow</h1>
					</div>
					<div class="centered" style="width: 10%;">
						<div data-id="separator"
							style="background-color: var(--r-main-color); height: 150px; width: 5%;"></div>
					</div>
					<div style="width: 50%; text-align: left;">
						<h1>PyTorch</h1>
					</div>
				</div>
				<aside class="notes">
					Let's again compare TensorFlow and PyTorch as an example.
					See if we can gain some insights from why PyTorch can win
					large number of users in an established market by
					TensorFlow.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width: 50%; text-align: right;">
						<h1>TensorFlow</h1>
						<h1>Google</h1>
					</div>
					<div class="centered" style="width: 10%;">
						<div data-id="separator"
							style="background-color: var(--r-main-color); height: 300px; width: 5%;"></div>
					</div>
					<div style="width: 50%; text-align: left;">
						<h1>PyTorch</h1>
						<h1>Meta</h1>
					</div>
				</div>
				<aside class="notes">
					TensorFlow is developed by Google. While PyTorch is
					developed by Meta.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width: 50%; text-align: right;">
						<h1>TensorFlow</h1>
						<h1>Google</h1>
						<h1>Engineering</h1>
					</div>
					<div class="centered" style="width: 10%;">
						<div data-id="separator"
							style="background-color: var(--r-main-color); height: 450px; width: 5%;"></div>
					</div>
					<div style="width: 50%; text-align: left;">
						<h1>PyTorch</h1>
						<h1>Meta</h1>
						<h1>Product</h1>
					</div>
				</div>
				<aside class="notes">
					Google is good at engineering. Meta is good at product.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<div style="width: 50%; text-align: right;">
						<h1>TensorFlow</h1>
						<h1>Google</h1>
						<h1>Engineering</h1>
						<h1>Fastest to run</h1>
					</div>
					<div class="centered" style="width: 10%;">
						<div data-id="separator"
							style="background-color: var(--r-main-color); height: 600px; width: 5%;"></div>
					</div>
					<div style="width: 50%; text-align: left;">
						<h1>PyTorch</h1>
						<h1>Meta</h1>
						<h1>Product</h1>
						<h1>Easiest to use</h1>
					</div>
				</div>
				<aside class="notes">
					TensorFlow is the fastest to run. PyTorch is the easiest to
					use for research scientists and all other model builders.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<h1>Easiest to use</h1>
				</div>
				<aside class="notes">
					This ease-of-usage is the key here.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<h1>Easiest to use</h1>
				</div>
				<div class="centered">
					<h1>Wins the community</h1>
				</div>
				<aside class="notes">
					The ease-of-usage is really important for the model builders
					in deep learning. They are usually research scientists who
					build the state-of-the-art models. All they care is how easy
					it is to build a model with the framework.

					So because PyTorch is the easiest framework to use, it wins
					in the community of deep learning research scientists. So
					all the state-of-the-art models are build with PyTorch.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<h1>Easiest to use</h1>
				</div>
				<div class="centered">
					<h1>Wins the community</h1>
				</div>
				<div class="centered">
					<h1>Propagate to the engineers</h1>
				</div>
				<aside class="notes">
					The engineers needs to put these state-of-the-art models to
					production. They do not want to re-implement the model in
					another framework. So they just make the deployment path for
					PyTorch models smoother. So now the engineers also prefer
					PyTorch.

					Although, PyTorch still has various problems, like it is
					generally slower than other frameworks, and hard to scale to
					large models. but people find ways to do it. A good example
					is OpenAI, they use PyTorch but they wrote their own engine
					to run PyTorch models.
				</aside>
			</section>
			<section data-auto-animate>
				<div class="centered">
					<h1>Easiest to use</h1>
				</div>
				<div class="centered">
					<h1>Wins the community</h1>
				</div>
				<div class="centered">
					<h1>Propagate to the engineers</h1>
				</div>
				<div class="centered">
					<h1>Establish ecosystem</h1>
				</div>
				<aside class="notes">
					With models the state-of-the-art models written in PyTorch
					and all the software build around it, like the ones for
					PyTorch model deployment, they established this ecosystem
					from the community. This really increases user retention.

					This is another important property of open source. You can
					establish an ecosystem that do not easily migrate away. And
					this is what all these deep learning frameworks trying to
					achieve.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1 class="r-fit-text">TensorFlow's blunders</h1>
				<aside class="notes">
					Let's also look at the other side. What did TensorFlow do
					wrong to give the chance to PyTorch to take away half of its
					users? The general user experience for TensorFlow 2 is OK.
					But there are a few basic things that TensorFlow did wrong
					that we want to learn from.
				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">TensorFlow's blunders</h1>
				<h2>
					<ul>
						<li>
							Installation
						</li>
					</ul>
				</h2>
				<aside class="notes">
					The first one is the installation guide. This is the very
					first step of a new user do when they want to use your open
					source software. It is really important but often
					overlooked.

					The installation guide for GPU on the official TensorFlow
					website had been broken for years. Then, they hired me.
					I discovered the problem. I coordinated multiple teams
					to get it resolved. So this fix happend totally by chance.
					There is no systematic way to get these issues resolved. but
					at least they hired the right people. Now, you can easily
					install it with a one-liner.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>TensorFlow's blunders</h1>
				<h2>
					<ul>
						<li>Installation</li>
						<li>Backword compatibility</li>
					</ul>
				</h2>
				<aside class="notes">
					The second one is the backward compatibility. TensorFlow 2
					is not compatible with TensorFlow 1. The APIs changed
					completely. The users needed to spend a lot of time and
					money to upgrade it. It causes a lot of discontent among the
					users. They would move to any framework other than
					TensorFlow.

					So installation and backward compatibility, these are
					important things you need to get right to have a good user
					experience before you do any fancy stuff.
				</aside>
			</section>
			<section>
				<h1>Invest heavily in UX</h1>
				<aside class="notes">
					To polish the UX, the frameworks has done a lot. All the
					deep learning framekwors are mainly implemented in C++, but
					had to wrap everything in Python just for easier usages.

					So you can think the Python code is just for polishing the
					UX. Let's take a look at the percentages of Python code in
					their repos. They are really trying to make the UX better.
				</aside>
			</section>
			<section id="python-percentage">
				<div class="centered" style="height: 300px">
					<div style="position:absolute;">
						<div class="fragment custom move-out-to-left" data-fragment-index="1">
							<h1>TensorFlow</h1>
						</div>
					</div>
					<div style="position:absolute;">
						<div class="fragment custom move-in-from-right" data-fragment-index="1">
							<div class="fragment custom move-out-to-left" data-fragment-index="2">
								<h1>PyTorch</h1>
							</div>
						</div>
					</div>
					<div style="position:absolute;">
						<div class="fragment move-in-from-right" data-fragment-index="2">
							<h1>JAX</h1>
						</div>
					</div>
				</div>
				<div class="centered">
					<div class="progress-container">
						<div class="progress-bar" id="progress-bar" style="width: 27%;">
							<div class="counter" id="counter" style="--percent: 26.91; font-size: 50px;"></div>
						</div>
					</div>
				</div>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h1>Polishing your UX is of high ROI</h1>
				<aside class="notes">
					They invested heavily in UX because it is of high ROI.
					Designing a good set of APIs is much easier. As long as you
					follow a set of simple design principles, it is totally
					achievable. How much engineering efforts do you need to get
					a deep learning framework to run faster or more robust?
				</aside>
			</section>
			<section>
				<h1>How to make software with good UX?</h1>
			</section>
			<section data-auto-animate>
				<h1 class="r-fit-text">Keras 3</h1>
				<aside class="notes">
					Before we dive in a few quick updates from the Keras team.
					Keras 3 has just been released with game-changing new features.

					Keras has been around for a comparatively long time as a
					developer interface sits on top of the deep learning
					frameworks.

					It supported Theano, MXNet, and TensorFlow.

				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">Keras 3</h1>
				<h2>
					<ul>
						<li>Support TensorFlow, JAX, PyTorch</li>
					</ul>
				</h2>
				<aside class="notes">
					Now, with Keras3, we officially support 3 backends:
					TensorFlow, JAX and PyTorch.

					Now, with one set of code, you get the benefits from all
					frameworks. The eager developing and debugging experience of
					PyTorch. Tap into the comprehensive tooling of the
					TensorFlow ecosystem. Faster training with JAX on TPU.

					Because of these benefits, it got adopted by MidJourney
					right away. They want the deployment path with PyTorch and
					want faster training with JAX.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Keras 3</h1>
				<h2>
					<ul>
						<li>Support TensorFlow, JAX, PyTorch</li>
						<li>Backward-compatible & future-proof</li>
					</ul>
				</h2>
				<aside class="notes">
					It is backward-compatible and future-proof. The Keras API
					has not been changed much ever since its very first release.
					You can easily migrate your code to Keras 3 with no changes
					unless you did something really special.

					Keras will continue to support any new backends in the
					future. If one day PyTorch is gone, and a new framework
					comes along, you still don't need to change your code.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Keras 3</h1>
				<h2>
					<ul>
						<li>Support TensorFlow, JAX, PyTorch</li>
						<li>Backward-compatible & future-proof</li>
						<li>Customizable with the NumPy API</li>
					</ul>
				</h2>
				<aside class="notes">
					NumPy API is the best API for tensor operations. You can
					easily find documentation, stack overflow answers, or ask
					ChatGPT to write the code. We implemented the NumPy API in
					Keras for you to customize your model. It works on all
					backends.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Keras 3</h1>
				<h2>
					<ul>
						<li>Support TensorFlow, JAX, PyTorch</li>
						<li>Backward-compatible & future-proof</li>
						<li>Customizable with the NumPy API</li>
						<li>Scalable with the distribution API</li>
					</ul>
				</h2>
				<aside class="notes">
					Finally, we have a set of backend-agnostic distributed APIs
					for you to easily shard your models and data, which is
					extremely useful for large models. More importantly, the
					distribution logic is totally separate from the model. You
					do not need to change anything of the model if you want to
					shard it differently.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1 class="r-fit-text">The 3 principles</h1>
				<aside class="notes">
					Now, I will present three simple yet powerful principles to make
					UX better. These are the most valuable knowledge I learned
					through the past few years working on Keras.
				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">The 3 principles</h1>
				<h2>from Keras</h2>
				<aside class="notes">
					Keras is a high-level API, and it is the best of its kind if
					considered independent of the underlying frameworks. And the
					high-level API is just about user experience. Here are the 3
					simple principles that we followed to ensure this user
					experience.
				</aside>
			</section>
			<section>
				<h2 class="nowrap">Principle 1</h2>
				<h1>Design end-to-end workflows</h1>
				<aside class="notes">
					Principle number one, design end-to-end workflows. So what
					does it mean?
				</aside>
			</section>
			<section>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				class Model:
					def __call__(self, input):
						"""The forward call of the model.

						Args:
							input: A tensor. The input to the model.
						"""
						pass
				</code></pre>
				<aside class="notes">
					When we think of designing the APIs of a piece of software,
					you may look like this. Define the class and add the
					documentations. Now, we know all the class names, method
					names, and the arguments. However, this would not help us
					understand much about the user experience.
				</aside>
			</section>
			<section>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				input = keras.Input(shape=(10,))
				x = layers.Dense(32, activation='relu')(input)
				output = layers.Dense(10, activation='softmax')(x)
				model = keras.models.Model(inputs=input, outputs=output)
				model.compile(
					optimizer='adam', loss='categorical_crossentropy'
				)
				</code></pre>
				<aside class="notes">
					What we should do is something like this. We want to write
					out the entire user workflow of using the software. Idealy,
					it should be a tutorial of how to use the software. It
					provides much more information about the user experience.
					It may help us spot much more UX problems during the design
					phase comparing with just write out the class and methdos.
				</aside>
			</section>
			<section>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				class RandomSearch:
					def __init__(self, ..., metrics, objective="val_loss", ...):
						"""The initializer.

						Args:
							metrics: A list of Keras metrics.
							objective: String or a custom metric function. The
								name of the metirc we want to minimize.
						"""
						pass
				</code></pre>
				<aside class="notes">
					Let's look at another example. This is from KerasTuner.
					We use this RandomSearch class to select the best model.
					We have the metrics, and objective in the arguments.
					by default objective equals validation loss. So, it helps us
					find the model with the smallest validation loss. Again, it
					doesn't provide much info about the user experience. So,
					everything looks OK for now.
				</aside>
			</section>
			<section data-auto-animate data-line-numbers>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				tuner = RandomSearch(
					...,
					metrics=[custom_metric],
					objective="val_???",
				)
				</code></pre>
				<aside class="notes">
					However, if we write an end-to-end workflow like this. It
					exposes much more problems. The user is trying to define a
					custom metric. The objective is not so straight-forward to
					use any more. What should we pass to the objective argument
					now? We easily spotted a user experience problem by writing
					this workflow.
				</aside>
			</section>
			<section data-auto-animate data-line-numbers>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				tuner = RandomSearch(
					...,
					metrics=[custom_metric],
					objective="val_custom_metric",
				)
				</code></pre>
				<aside class="notes">
					Actually, it should be just "val_custom_metric". But,
					obviously, it is not intuitive enough. We want to make it
					better instead of forcing the user to learn this.
				</aside>
			</section>
			<section data-auto-animate data-line-numbers>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				def custom_metric(y_true, y_pred):
					squared_diff = ops.square(y_true - y_pred)
					return ops.mean(squared_diff, axis=-1)

				tuner = RandomSearch(
					...,
					metrics=[custom_metric],
					objective="val_custom_metric",
				)
				</code></pre>
				<aside class="notes">
					Another thing is that, if you wrote the design more
					comprehensively, you will find you even need to learn how to
					write a Keras custom metric. We have strict requirements
					for the signature of this function. It has to be compatible
					with Keras.
				</aside>
			</section>
			<section>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				class MyHyperModel(HyperModel):
					def fit(self, trial, model, validation_data):
						x_val, y_true = validation_data
						y_pred = model(x_val)
						return custom_metric(y_true, y_pred)

				tuner = RandomSearch(MyHyperModel(), max_trials=20)
				</code></pre>
				<aside class="notes">
					After discovering this problem. We specially designed a
					better workflow for custom metrics. You only need to
					override the `fit` function, compute your custom metric and
					return it. The UX is much better right now.
				</aside>
			</section>
			<section>
				<h1>UX <i class="bi bi-arrow-right"></i> Implementation</h1>
			</section>
			<aside class="notes">
				One more thing to remember is we should always start from the
				UX. The designed workflows deside the implementation.
			</aside>
			<section>
				<h2 class="nowrap">Principle 2</h2>
				<h1>Minimize cognitive load</h1>
				<aside class="notes">
					Principle number two, minimize the cognitive load for the
					user when learning to use your software. Do not force the
					user to learn anything unless it is really necessary. Let's
					see some good examples.
				</aside>
			</section>
			<section>
				<h2>Good example: Keras modeling</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				model = keras.Sequential([
					layers.Dense(10, activation="relu"),
					layers.Dense(num_classes, activation="softmax"),
				])
				model.compile(loss='categorical_crossentropy')
				model.fit(...)
				model.predict(...)
				</code></pre>
				<aside class="notes">
					One good example is the Keras modeling API, which is pretty
					intuitive. The model builders already have these concepts
					in mind, like a model is a stack of layers. It needs a loss
					function. We can fit it with data or make it predict on
					data. So basically, no new concepts learned in order to use
					Keras.
				</aside>
			</section>
			<section>
				<h2>Good example: PyTorch modeling</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
					class MyModel(nn.Module):
						def forward(self, x):
							if x.sum() > 0:
								return self.path_a(x)
							return self.path_b(x)
				</code></pre>
				<aside class="notes">
					Another good example is the PyTorch modeling. The code is
					executed just like Python code. All tensors are just real
					tensors with real values. You can depend on the value of a
					tensor to decide your path with plain Python code.
				</aside>
			</section>
			<section>
				<h2>Bad example: Keras with JAX or TensorFlow</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
					class MyModel(keras.Model):
						def call(self, x):
							return ops.cond(
								ops.sum(inputs) > 0,
								lambda : self.path_a(inputs),
								lambda : self.path_b(inputs),
							)
				</code></pre>
				<aside class="notes">
					You can also do this with Keras with TensorFlow or JAX
					backend, but needs to be written in a different way. All
					the if conditions need to be written with this ops.cond
					function. This is less intuitive which is bad. In
					compensation, it brings significant improvement in training
					speed. But from a UX perspective, it is bad.
				</aside>
			</section>
			<section>
				<h2>Bad example: PyTorch memory and speed optimization</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				torch.relu(x, inplace=True)
				x = torch._foreach_add(x, y)
				torch._foreach_add_(x, y)
				x.cuda()
				</code></pre>
				<aside class="notes">
					Here is the catch of the flexibiliy of PyTorch. You would
					have to optimize the memory and speed by yourself. It
					introduced these APIs and new concepts to do so, like the
					inplace arguments for the ops, The parallel ops API and
					explicit device placement.
				</aside>
			</section>
			<section>
				<h2>Bad example: PyTorch compute gradients</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers="1-6|5" class="language-python">
				inputs, labels = batch
				outputs = model(inputs)
				loss = torch.nn.functional.cross_entropy(outputs, labels)
				optimizer.zero_grad()
				loss.backward()
				optimizer.step()
				</code></pre>
				<aside class="notes">
					Another bad example is loss.backward. It computes the
					gradients. This is introducing a new concept of actually
					computing the gradients. I don't think the user has to know
					about it.
				</aside>
			</section>
			<section>
				<h2>Good examples:</h2>
				<h1>keras.ops, tf.numpy, jax.numpy</h1>
				<aside class="notes">
					Some other good examples are keras.ops, tensorflow.numpy,
					jax.numpy. They are just reimplementation of the numpy API.
					When you have to introduce some cognitive load, just reuse
					what people are already familiar with. We have to provide
					some low level ops in these frameworks, right? Instead of
					let people learn a new set of APIs, which may have a hundred
					functions, we just use the most popular existing API for it.
				</aside>
			</section>
			<section>
				<h2>Worst case:</h2>
				<h1>Trick the users</h1>
				<aside class="notes">
					Here is the worst thing you can do with user experience:
					Trick the users. Trick the user to believe your API is
					something else than what it really is.
				</aside>
			</section>
			<section data-auto-animate>
				<h2>Really bad example: How to pad the images?</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				import torch.nn.functional as F
				# pad the 32x32 images to (1+32+1)x(2+32+2)
				# (100, 3, 32, 32) to (100, 3, 34, 36)
				</code></pre>
				<aside class="notes">
					Here are some examples. How can you pad image tensors in
					PyTorch? The image size here is 32 by 32. We want to pad
					zeros at the begining and end of each dimension, and make it
					into 1 plus 32 plus 1 by 2 plus 32 by 2. So the input shape
					is 100 images, 3 channels, 32 by 32. The output shape is 100
					images, 3 channels, 34 by 36.
				</aside>
			</section>
			<section data-auto-animate>
				<h2>Really bad example: How to pad the images?</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				import torch.nn.functional as F
				# pad the 32x32 images to (1+32+1)x(2+32+2)
				# (100, 3, 32, 32) to (100, 3, 34, 36)
				out = F.pad(
					torch.empty(100, 3, 32, 32),
					pad=((0, 0), (0, 0), (1, 1), (2, 2)),
				)
				</code></pre>
				<aside class="notes">
					The intuitive way would be like this. 4 tuples of integers,
					each corresponds to the zeros added to the begining and end
					of the 4 dimensions of the input tensor. Or we can just omit
					the leading zeros.
				</aside>
			</section>
			<section data-auto-animate>
				<h2>Really bad example: How to pad the images?</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				import torch.nn.functional as F
				# pad the 32x32 images to (1+32+1)x(2+32+2)
				# (100, 3, 32, 32) to (100, 3, 34, 36)
				out = F.pad(
					torch.empty(100, 3, 32, 32),
					pad=(2, 2, 1, 1),
				)
				</code></pre>
				<aside class="notes">
					However, the correct answer is this. You need to pass them
					as a single tuple. And what more strange is that you need to
					reverse the order of the sequence.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h2>Really bad example: What is the output?</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				value = True

				@tf.function
				def get_value():
					return value

				value = False
				print(get_value())
				# False?
				</code></pre>
				<aside class="notes">
					Let's see another really bad example from TensorFlow. This
					code snippet. Will it print True or False? First, we define
					the value as true. Then, we define a function to return the
					value, and decorated it as a tf function. Then, we change
					the value to False. What is the return value if we call the
					function, now? Intuitively, it should be false, right?
				</aside>
			</section>
			<section data-auto-animate>
				<h2>Really bad example: What is the output?</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
				value = True

				@tf.function
				def get_value():
					return value

				value = False
				print(get_value())
				# True!
				</code></pre>
				<aside class="notes">
					But, actually, it prints true because the function is
					compiled and all python variables are treated as constants.
				</aside>
			</section>
			<section>
				<h2 class="nowrap">Principle 3</h2>
				<h1>Interaction over documentation</h1>
				<aside class="notes">
					Principle number 3, interaction over documentation. No one
					likes to read long documentations if they can figure it out
					just by trying out the software by themselves. So, APIs
					should follow the same logic.
				</aside>
			</section>
			<section>
				<h2>Good example: PyTorch inplace ops</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
					x = x.add(y)
					x.add_(y)
					x = x.mul(y)
					x.mul_(y)
				</code></pre>
				<aside class="notes">
					Here is a good example. In PyTorch, all methods with the
					underscore are inplace ops, while the ones without are not.
					From a interactive perspective, these are good, because they
					are easy to follow, and the users do not need to check the
					docs everytime they want the inplace version of a method.
					but, of course, they introduced cognitive load. The users
					need to know what does inplace mean.
				</aside>
			</section>
			<section>
				<h2>Good example: Keras layers</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
					from keras import layers

					layers.MaxPooling2D()
					layers.GlobalMaxPooling1D()
					layers.GlobalAveragePooling3D()
				</code></pre>
				<aside class="notes">
					Another good example is the Keras layers. They strictly
					follow the same naming convention. With a clear naming
					convention, the users can easily remember the layer names
					without checking documentation.
				</aside>
			</section>
			<section>
				<h2>Print helpful error messages</h2>
				<pre class="fragment fade-in" data-id="code-animation"><code data-trim data-line-numbers class="language-python">
					# Bad example:
					raise ValueError("Tensor shape mismatch.")
					# Good example:
					raise ValueError(
						"Tensor shape mismatch. "
						"Expected: (batch, num_features). "
						f"Received: {x.shape}"
					)
				</code></pre>
				<aside class="notes">
					Another important part of interaction between the developer
					and the software is the error message. We should always do
					th necessary checks in the code and try to print helpful
					error messages.

					Let's see these examples. The first one has not much
					information. Just says tensor shape mismatch. While the
					second one contains much more useful information for the
					user to find the bug. It not only tells you the error is
					because of tensor shape mismatch, it also shows what is the
					expected shape and what is the wrong shape passed to it. If
					you did not mean to pass that shape, you have a better idea
					of the bug now.
				</aside>
			</section>
			<section data-auto-animate>
				<h2>Best example: give the instructions directly</h2>
				<pre data-id="code-animation"><code data-trim data-line-numbers class="language-python">
					import math

					math.sqr(4)
					"AttributeError: module 'math' has no attribute 'sqr'. Did you mean: 'sqrt'?"
				</code></pre>
				<aside class="notes">
					The best error message would be directly pointing the user
					to the fix. This is a general Python error message. It
					guessed what is wrong with the code and directly pointed the
					user to the fix.
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="text-align: left;">
						<h2>Principle 1: Design end-to-end workflows</h2>
						<h2>Principle 2: Minimize cognitive load</h2>
						<h2>Principle 3: Interaction over documentation</h2>
					</div>
				</div>
				<aside class="notes">
					OK. That are the three principles we follow. So far, our
					design work is done. However,
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1>The devil is in the details</h1>
				<aside class="notes">
					The devil is in the details.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>The devil is in the details</h1>
				<h2>
					<ul>
						<li>Bugs</li>
						<li>New features</li>
						<li>Documentations</li>
					</ul>
				</h2>
				<aside class="notes">
					It is because the devil is in the details. The bug fixes,
					developing new features and polish documentation There are
					just too many details to figure out. You need the resources
					to do these. So you need to ...
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1 class="r-fit-text">Community contributions</h1>
				<aside class="notes">
					Leverage community contributions. We cannot talk about open
					source without mentioning the community.
				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">Community contributions</h1>
				<h2>
					<ul>
						<li>Product excellence</li>
					</ul>
				</h2>
				<aside class="notes">
					Here are some reasons why you should leverage community
					contributions. You will have a lot of contributors to help
					you polish your software, removing the pain points they saw
					during their usages.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Community contributions</h1>
				<h2>
					<ul>
						<li>Product excellence</li>
						<li>Gain user trust</li>
					</ul>
				</h2>
				<aside class="notes">
					Another more important reason is that it helps you gain user
					trust. The users can reach into your codebase to fix bugs,
					add documentation, or implement new features. In this way,
					they feel more confident in using your software, because
					they do not need to worry about they encounter a serious bug
					in the future that they can never fix.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Community contributions</h1>
				<h2>
					<ul>
						<li>Product excellence</li>
						<li>Gain user trust</li>
						<li>Key to establish an ecosystem</li>
					</ul>
				</h2>
				<aside class="notes">
					And user trust is the key to establish an ecosystem based on
					your software. They will not base their code on your
					software unless they have enough trust in it.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1>How to gain community contributors?</h1>
				<aside class="notes">
					If it is so important to leverage community contributions,
					the question now is how to gain community contributors for
					your software.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>How to gain community contributors?</h1>
				<h2>
					<ul>
						<li data-id="gain">
							<span>Gain more users</span>
							<span class="fragment fade-in">
								<i class="bi bi-arrow-right"></i>
								<span>contributors</span>
							</span>
						</li>
					</ul>
				</h2>
				<aside class="notes">
					The first step is to gain more users with all the techniques
					we introduced just now. Because the contributors all came
					from the users. The larger the user base is, the more
					contributors you have.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>How to gain community contributors?</h1>
				<h2>
					<ul>
						<li data-id="gain">
							<span>Gain more users</span>
							<i class="bi bi-arrow-right"></i>
							<span>contributors</span>
						</li>
						<li>
							Make it contributor-friendly
						</li>
					</ul>
				</h2>
				<aside class="notes">
					The second important thing is to make your project
					contributor-friendly. Otherwise, you will drive the
					attracted contributors away when they find it hard to
					contribute to your project.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h2 class="r-fit-text">The $1M metric</h2>
				<aside class="notes">
					Here I would like to introduce our million-dollar metric in
					optimizing contributor experience to Keras. We have spend
					at least 1 million dollar of engineering resource on it.
				</aside>
			</section>
			<section data-auto-animate>
				<h2 class="nowrap">The $1M metric</h2>
				<h1>Average life span of pull requests</h1>
				<aside class="notes">
					It is the average life span of pull requests. How long does
					it take for a pull request to get merged in your project?
					Two years ago, we separated Keras codebase from tensorflow
					and put it into its own GitHub repo just to optimize this
					metric. Because running the tests for a pull request for
					TensorFlow takes too long, but it is much shorter for Keras.
					To avoid running the tests, we moved to a separate repo.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1>A bad contributing experience</h1>
				<aside class="notes">
					Let's see what a bad contributing experience looks like.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A bad contributing experience</h1>
				<h2>
					<ul>
						<li>Breaks the code style</li>
					</ul>
				</h2>
				<aside class="notes">
					You may accidentally break the code styles. You did not even
					notice before the first reviewer pointed it out.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A bad contributing experience</h1>
				<h2>
					<ul>
						<li>Breaks the code style</li>
						<li>Breaks the unit tests</li>
					</ul>
				</h2>
				<aside class="notes">
					You may also break some unit tests. No one knew it until all
					the reviews and code revisions finished. The PR is about to
					merge and failed an internal CI test.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A bad contributing experience</h1>
				<h2>
					<ul>
						<li>Breaks the code style</li>
						<li>Breaks the unit tests</li>
						<li>Cannot run these locally</li>
					</ul>
				</h2>
				<aside class="notes">
					What made it worse is that the test cannot run locally.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A bad contributing experience</h1>
				<h2>
					<ul>
						<li>Breaks the code style</li>
						<li>Breaks the unit tests</li>
						<li>Cannot run these locally</li>
						<li>Relies on CI to debug</li>
					</ul>
				</h2>
				<aside class="notes">
					You can only rely on the CI to run the tests. It means you
					change your code and ask the reviewer to run it for you.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A bad contributing experience</h1>
				<h2>
					<ul>
						<li>Breaks the code style</li>
						<li>Breaks the unit tests</li>
						<li>Cannot run these locally</li>
						<li>Relies on CI to debug</li>
						<li>Multiple rounds of review to fix</li>
					</ul>
				</h2>
				<aside class="notes">
					This may take multiple rounds to get it fixed.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1>A good contributing experience</h1>
				<aside class="notes">
					Let's take a look at what a good contributing experience
					looks like.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A good contributing experience</h1>
				<h2>
					<ul>
						<li>Easy to setup the dev env</li>
					</ul>
				</h2>
				<aside class="notes">
					First, it is easy to setup the development environment.
					There should be a list of simple steps to follow.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A good contributing experience</h1>
				<h2>
					<ul>
						<li>Easy to setup the dev env</li>
						<li>Run all the checks locally</li>
					</ul>
				</h2>
				<aside class="notes">
					All the checks should be runnable locally by the
					contributor. This might be hard if the test is running on a
					GPU or TPU, but we at least should make sure the code style
					checks and unit tests can all run locally instead of leaving
					them to the code reviewers.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>A good contributing experience</h1>
				<h2>
					<ul>
						<li>Easy to setup the dev env</li>
						<li>Run all the checks locally</li>
						<li>Code review focus on important things</li>
					</ul>
				</h2>
				<aside class="notes">
					We got all these things checked by the contributor locally.
					So that the code review only focus on the important things.
				</aside>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1>Contributor-friendly project setup</h1>
				<aside class="notes">
					To achieve this good contributing experience, we did the
					following things to setup our repo to make it friendly to
					the contributors.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Contributor-friendly project setup</h1>
				<h2>
					<ul>
						<li>Config devcontainers (GitHub Codespaces)</li>
					</ul>
				</h2>
				<aside class="notes">
					We support devcontainers. It means you can start
					contributing with one-click on the GitHub webpage. All the
					dependencies are installed there for you already.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Contributor-friendly project setup</h1>
				<h2>
					<ul>
						<li>Config devcontainers (GitHub Codespaces)</li>
						<li>Instructions for running tests (single & all)</li>
					</ul>
				</h2>
				<aside class="notes">
					We have clear instructions on how to run the unit tests
					locally for both run a specific single test or the entire
					test suite.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Contributor-friendly project setup</h1>
				<h2>
					<ul>
						<li>Config devcontainers (GitHub Codespaces)</li>
						<li>Instructions for running tests (single & all)</li>
						<li>Short CI time</li>
					</ul>
				</h2>
				<aside class="notes">
					We have a rather short CI time by parallelizing the
					different testing environments.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Contributor-friendly project setup</h1>
				<h2>
					<ul>
						<li>Config devcontainers (GitHub Codespaces)</li>
						<li>Instructions for running tests (single & all)</li>
						<li>Short CI time</li>
						<li>Auto-format the code</li>
					</ul>
				</h2>
				<aside class="notes">
					The code are mostly auto formatted to avoid 90% of the code
					style issues before they are committed.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Contributor-friendly project setup</h1>
				<h2>
					<ul>
						<li>Config devcontainers (GitHub Codespaces)</li>
						<li>Instructions for running tests (single & all)</li>
						<li>Short CI time</li>
						<li>Auto-format the code</li>
						<li>Contributing guide</li>
					</ul>
				</h2>
				<aside class="notes">
					A clear contributing guide to walk through the contributing
					process step by step.
				</aside>
			</section>
			<section>
				<h1>What are the new opportunities</h1>
				<h1>in open-source AI?</h1>
				<aside class="notes">
					So far I have shared everything about developing an awesome
					open-source software in AI. Now, the question is what
					project exactly should you work on?
				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="r-fit-text">Models</h1>
				<aside class="notes">
					The short answer is models. Users need models. In the past
					couple of years, we saw this shift from building your own
					model to fine-tuning foundational models. It will become
					even more true in the next few years.

					In an extreme case, you may just publish one fundational
					model as a stand-alone project by wrapping an open-source
					model.

					It has a lower requirements for software engineering skills
					comparing the developing new deep learning frameworks. You
					may have wider audience as more and more people are using
					AI.
				</aside>
			</section>
			<section data-auto-animate>
				<h1>Models</h1>
				<h2>
					<ul>
						<li>High-quality code</li>
						<li class="fragment fade-in">Modularized components</li>
						<li class="fragment fade-in">Well-aligned APIs</li>
						<li class="fragment fade-in">Minimal dependencies</li>
					</ul>
				</h2>
				<aside class="notes">
					I believe a good model library should have the following
					characteristics.
				</aside>
			</section>
			<section>
				<h1 class="r-fit-text">
					<div>
						KerasCV
					</div>
					<div>
						KerasNLP
					</div>
				</h1>
				<aside class="notes">
					With these in mind, we developed KerasCV and KerasNLP. You
					are welcome to check them out. but there are definitely more
					opportunity out there for you to develop your own library.
				</aside>
			</section>
			<section>
				<h1>New concerns on open-source models</h1>
				<aside class="notes">
					Finally, this trend of open source models also raised some
					new concerns.
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="width: 500px;">
						<img style="border-radius: 10%;" src="/img/yann-lecun.jpg">
					</div>
					<div style="width: 200px;">
					</div>
					<div class="fragment fade-in" style="width: 800px;">
						<h2>"Could the SkyNet take-over in Terminator have happened if SkyNet had been open source?"
						</h2>
						<br>
						<h3>--Yann LeCun</h3>
					</div>
				</div>
				<aside class="notes">
					First, let's see what the open source advocates say. The
					most famous one is Yann LeCun. This is what he posted on
					Twitter. "Could the SkyNet take-over in Terminator have
					happend if SkyNet had been open source?" His point is with
					open source, we can spot the problems in the models and fix
					them early before the cause any serious harm.

					To add to that point, this LLM trend is inevitable. Its
					impact on the society is unpredictable. We are still in an
					early stage. If we just throw out these models to the open
					public, and see what problem it is causing, for example, see
					how people are abusing it and think about how we can reduce
					the harm, it is at least better than the models got
					accidentally leaked some how when they got really dangerous,
					and we are not prepared for it.
				</aside>
			</section>
			<section>
				<div class="centered">
					<div style="width: 500px;">
						<img style="border-radius: 10%;" src="/img/eric-schmidt.jpg">
					</div>
					<div style="width: 200px;">
					</div>
					<div class="fragment fade-in" style="width: 800px;">
						<h2>"Make sure these things are not misused by evil people."</h2>
						<br>
						<h3>--Eric Schmidt</h3>
					</div>
				</div>
				<aside class="notes">
					On the other side, the former Google CEO, Eric Schmidt also
					warn us that we should make sure these things are not
					misused by evil people. The raw models could be really
					dangerous in the future. They are super-intelligence. They
					could be used as weapons.
					This argument may take a long time to be settled. It is
					something that worth everyone to think about.
				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="r-fit-text">Quick Review</h1>
				<aside class="notes">
					That is all the content of the presentation. Let's have a
					quick review of what we learned today.
				</aside>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">Quick Review</h1>
				<br>
				<h3 class="centered">
					<ul style="width:1000px;">
						<li>What is open-source?</li>
						<ul class="fragment fade-in">
							<li>Open access</li>
							<li>Open collaboration</li>
						</ul>
						<li class="fragment fade-in">Why do we open-source?</li>
						<ul class="fragment fade-in">
							<li>Free code</li>
							<li>Paid service</li>
						</ul>
						<li class="fragment fade-in">How to do open-source?</li>
						<ul class="fragment fade-in">
							<li>Design end-to-end workflows</li>
							<li>Reduce cognitive load</li>
							<li>Interaction over documentation</li>
						</ul>
					</ul>
					<ul>
						<li class="fragment fade-in">Why community contributions?</li>
						<ul class="fragment fade-in">
							<li>Product excellence</li>
							<li>User trust</li>
							<li>Establish ecosystem</li>
						</ul>
						<li class="fragment fade-in">How to gain contributors?</li>
						<ul class="fragment fade-in">
							<li>More users</li>
							<li>$1m metric: average PR life</li>
						</ul>
						<li class="fragment fade-in">What's next?</li>
						<ul class="fragment fade-in">
							<li>Models</li>
						</ul>
						<li class="fragment fade-in">Should we opens-source LLMs?</li>
					</ul>
				</h3>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1 class="r-fit-text">The next episode</h1>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">The next episode</h1>
				<h2>How do deep learning frameworks work?</h2>
				<h2 class="fragment fade-in">from Python to GPUs</h2>
				<h2 class="fragment fade-in">What are deep learning compilers?</h2>
				<h2 class="fragment fade-in">How are TVM, XLA, Triton all about?</h2>
				<h2 class="fragment fade-in">Why TPUs are faster?</h2>
				<h2 class="fragment fade-in">What are new challenges posed by LLMs?</h2>
			</section>
			<section data-auto-animate data-auto-animate-restart>
				<h1 class="r-fit-text">Thank you!</h1>
			</section>
			<section data-auto-animate>
				<h1 class="nowrap">Thank you!</h1>
				<h1><br></h1>
				<div class="centered">
					<div style="text-align: left;">
						<h2>
							<i class="bi-envelope-fill" style="margin-right:10px;"></i> <span>haifeng.jin@pm.me</span>
						</h2>
						<h2>
							<i class="bi-medium" style="margin-right:10px;"></i> <span>Haifeng Jin</span>
						</h2>
					</div>
				</div>
				<aside class="notes">
				</aside>
			</section>
			<div class="my-slide-number"> 1 </div>
		</div>
	</div>

	<script src="/js/reveal.min.js"></script>
	<script src="/js/notes.min.js"></script>
	<script src="/js/highlight.min.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,

			// Set presentation resolution
			width: 1920,
			height: 1080,

			// Display presentation control arrows
			controls: false,

			// Display slide number to false
			// Add my own element under <slides>
			slideNumber: false,

			// Display a presentation progress bar
			progress: false,

			// Transition style
			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// Transition speed
			transitionSpeed: 'default', // default/fast/slow

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealHighlight, RevealNotes]
		});

		var current_slide = 0;

		Reveal.on('slidechanged', event => {
			// Changing slide number.
			current_slide = event.currentSlide;
			var element = document.getElementsByClassName('my-slide-number')[0];
			element.innerHTML = Reveal.getIndices(event.currentSlide).h + 1;
		});

		var progress_indices = {
			"tensorflow": 0,
			"chrome": 0,
			"android": 0,
			"python-percentage": 0,
		};
		var progress_values = [26.91, 48.41, 92.61];

		Reveal.on('fragmentshown', event => {
			progress_index = ++progress_indices[current_slide.id];
			if (current_slide.id == "chrome" && progress_index == 2) {
				setTimeout(Reveal.next, 300);
				setTimeout(Reveal.next, 300);
			}
			if (current_slide.id == "android" && progress_index == 1) {
				setTimeout(Reveal.next, 300);
				setTimeout(Reveal.next, 300);
			}
			if (current_slide.id == "python-percentage") {
				value = progress_values[progress_index]
				document.getElementById("progress-bar").style.width = value + "%";
				document.getElementById("counter").style.setProperty("--percent", value);
			}
		});

		Reveal.on('fragmenthidden', event => {
			progress_index = --progress_indices[current_slide.id];
			if (progress_index < 0) {
				progress_index = progress_indices[current_slide.id] = 0;
			}

			if (current_slide.id == "chrome" && progress_index == 0) {
				setTimeout(Reveal.prev, 300);
				setTimeout(Reveal.prev, 300);
			}
			if (current_slide.id == "tensorflow" && progress_index == 0) {
				setTimeout(Reveal.prev, 300);
				setTimeout(Reveal.prev, 300);
			}
			if (current_slide.id == "python-percentage") {
				value = progress_values[progress_index]
				document.getElementById("progress-bar").style.width = value + "%";
				document.getElementById("counter").style.setProperty("--percent", value);
			}
		});
	</script>
</body>

</html>